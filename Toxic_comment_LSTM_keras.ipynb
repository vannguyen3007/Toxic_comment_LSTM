{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Toxic comment LSTM keras.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ys5MH_2qdkod"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQOtoGqeiVuB"
      },
      "source": [
        "def get_coefs(word1, *arr):\n",
        "    return word1, np.asarray(arr, dtype='float32')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNL2ITZyiXZB"
      },
      "source": [
        "# size of each word vector\n",
        "embed_size = 300\n",
        "# number of rows in the embedding vector (unique words)\n",
        "max_features = 100000\n",
        "# max words in a comment; pad if not this length\n",
        "maxlen = 150\n",
        "batch_size = 128\n",
        "epochs = 2\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YVVtfKwiZQu"
      },
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcKVsF4Pkas4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "39408163-6bd2-490c-e7a3-dc958563ff04"
      },
      "source": [
        "train.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  ... identity_hate\n",
              "0  0000997932d777bf  ...             0\n",
              "1  000103f0d9cfb60f  ...             0\n",
              "2  000113f07ec002fd  ...             0\n",
              "\n",
              "[3 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCXwc7ENkchT"
      },
      "source": [
        "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
        "y = train[list_classes].values\n",
        "tokenizer = Tokenizer(num_words=max_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJ9YFGJYkejs"
      },
      "source": [
        "list_sentences_train = train[\"comment_text\"].fillna(\"_na_\").values\n",
        "list_sentences_test = test[\"comment_text\"].fillna(\"_na_\").values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_1FyMEVkgGS"
      },
      "source": [
        "tokenizer.fit_on_texts(list(list_sentences_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FImc3PDAkhi3"
      },
      "source": [
        "list_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\n",
        "list_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0enBFUE5klTj"
      },
      "source": [
        "X_tr = pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
        "X_te = pad_sequences(list_tokenized_test, maxlen=maxlen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5BpuuSalFjr"
      },
      "source": [
        "def get_embed_mat(EMBEDDING_FILE, max_features=20000):\n",
        "    # word vectors\n",
        "    embeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open('embeddings/glove.840B.300d.txt', encoding='utf8'))\n",
        "    print('Found %s word vectors.' % len(embeddings_index))\n",
        "\n",
        "    # embedding matrix\n",
        "    word_index = tokenizer.word_index\n",
        "    num_words = min(max_features, len(word_index) + 1)\n",
        "    all_embs = np.stack(embeddings_index.values()) #for random init\n",
        "    embedding_matrix = np.random.normal(all_embs.mean(), all_embs.std(), \n",
        "                                        (num_words, embed_dim))\n",
        "    for word, i in word_index.items():\n",
        "        if i >= max_features:\n",
        "            continue\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "    max_features = embedding_matrix.shape[0]\n",
        "\n",
        "    return max_features, embedding_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2l55pbhlRTw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7db77c7-81f7-49e8-a4e4-da3a5ed7bb3d"
      },
      "source": [
        "%%time\n",
        "import zipfile\n",
        "!wget http://nlp.stanford.edu/data/glove.840B.300d.zip\n",
        "zip_file = zipfile.ZipFile('glove.840B.300d.zip')\n",
        "zip_file.extractall('./embeddings/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-16 05:44:17--  http://nlp.stanford.edu/data/glove.840B.300d.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.840B.300d.zip [following]\n",
            "--2020-11-16 05:44:17--  https://nlp.stanford.edu/data/glove.840B.300d.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.840B.300d.zip [following]\n",
            "--2020-11-16 05:44:17--  http://downloads.cs.stanford.edu/nlp/data/glove.840B.300d.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2176768927 (2.0G) [application/zip]\n",
            "Saving to: ‘glove.840B.300d.zip’\n",
            "\n",
            "glove.840B.300d.zip 100%[===================>]   2.03G  2.06MB/s    in 16m 54s \n",
            "\n",
            "2020-11-16 06:01:11 (2.05 MB/s) - ‘glove.840B.300d.zip’ saved [2176768927/2176768927]\n",
            "\n",
            "CPU times: user 43.9 s, sys: 5.81 s, total: 49.7 s\n",
            "Wall time: 18min 47s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXoKDtTzp46b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb5198d7-a8b5-4a0f-9cd2-c3b1b75d7e8a"
      },
      "source": [
        "embeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open('embeddings/glove.840B.300d.txt', encoding='utf8'))\n",
        "all_embs = np.stack(embeddings_index.values())\n",
        "emb_mean, emb_std = (all_embs.mean(), all_embs.std())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  if self.run_code(code, result):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0apxmlwkk9Fx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c8daa1b-c435-4cdc-beb7-bb2ec3a6bcd3"
      },
      "source": [
        "\n",
        "print (\"Mean and SD of embedding %s, %s\" % (emb_mean, emb_std))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean and SD of embedding -0.005838499, 0.48782197\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5VZp9MMqyJU"
      },
      "source": [
        "word_index = tokenizer.word_index\n",
        "nb_words = min(max_features, len(word_index))\n",
        "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
        "for word, i in word_index.items():\n",
        "    if i >= max_features:\n",
        "        continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a66dwBovrzqL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c83a461-26d4-4d57-9345-ded1e0d66a9c"
      },
      "source": [
        "inp = Input(shape=(maxlen,))\n",
        "x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
        "x = Bidirectional(LSTM(batch_size, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))(x)\n",
        "x = GlobalMaxPool1D()(x)\n",
        "x = Dense(batch_size, activation=\"relu\")(x)\n",
        "x = Dropout(0.1)(x)\n",
        "x = Dense(6, activation=\"sigmoid\")(x)\n",
        "model = Model(inputs=inp, outputs=x)\n",
        "early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5)\n",
        "callbacks_list = [early]\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-3), metrics=['accuracy'])\n",
        "model.summary()\n",
        "model.fit(X_tr, y, batch_size=batch_size, epochs=epochs, validation_split=0.1, callbacks=callbacks_list)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 150)]             0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 150, 300)          30000000  \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 150, 256)          439296    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 6)                 774       \n",
            "=================================================================\n",
            "Total params: 30,472,966\n",
            "Trainable params: 30,472,966\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/2\n",
            "1122/1122 [==============================] - ETA: 0s - loss: 0.2750 - accuracy: 0.9901WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "1122/1122 [==============================] - 1544s 1s/step - loss: 0.2750 - accuracy: 0.9901 - val_loss: 0.2698 - val_accuracy: 0.9925\n",
            "Epoch 2/2\n",
            "1122/1122 [==============================] - ETA: 0s - loss: 0.2591 - accuracy: 0.9934WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "1122/1122 [==============================] - 1561s 1s/step - loss: 0.2591 - accuracy: 0.9934 - val_loss: 0.2693 - val_accuracy: 0.9939\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6902071780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cfj99hz6r3b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4bb2a52-4b26-4b9d-dc40-f280b0f93942"
      },
      "source": [
        "y_predict = model.predict([X_te], batch_size=1024, verbose=1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "150/150 [==============================] - 23s 154ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAcj6spQ4Muc"
      },
      "source": [
        "sample_submission = pd.read_csv('sample_submission.csv')\n",
        "sample_submission[list_classes] = y_predict\n",
        "sample_submission.to_csv('submission_lstm_keras.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtBbuN5-4V0n"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}